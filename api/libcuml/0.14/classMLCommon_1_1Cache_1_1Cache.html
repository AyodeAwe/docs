<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta content="text/xhtml;charset=utf-8" http-equiv="Content-Type"/>
  <meta content="IE=9" http-equiv="X-UA-Compatible"/>
  <meta content="Doxygen 1.8.18" name="generator"/>
  <meta content="width=device-width, initial-scale=1" name="viewport"/>
  <title>
   cuML C++ API: MLCommon::Cache::Cache&lt; math_t, associativity &gt; Class Template Reference
  </title>
  <link href="tabs.css" rel="stylesheet" type="text/css"/>
  <script src="jquery.js" type="text/javascript">
  </script>
  <script src="dynsections.js" type="text/javascript">
  </script>
  <link href="search/search.css" rel="stylesheet" type="text/css"/>
  <script src="search/searchdata.js" type="text/javascript">
  </script>
  <script src="search/search.js" type="text/javascript">
  </script>
  <script type="text/x-mathjax-config">
   MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
  </script>
  <script async="async" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js" type="text/javascript">
  </script>
  <link href="doxygen.css" rel="stylesheet" type="text/css"/>
  <link href="https://stackpath.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" id="rapids-fa-tag" rel="stylesheet"/>
  <link href="/assets/css/custom.css" id="rapids-selector-css" rel="stylesheet"/>
 </head>
 <body>
  <div id="top">
   <!-- do not remove this div, it is closed by doxygen! -->
   <div id="titlearea">
    <div id="rapids-doxygen-container">
     <div class="rapids-home-container">
      <a class="rapids-home-container__home-btn" href="/api">
       Home
      </a>
     </div>
     <div class="rapids-selector__container rapids-selector--hidden">
      <div class="rapids-selector__selected">
       libcuml
      </div>
      <div class="rapids-selector__menu">
       <a class="rapids-selector__menu-item" href="/api/clx/stable/api.html">
        clx
       </a>
       <a class="rapids-selector__menu-item" href="/api/cudf/stable/api.html">
        cudf
       </a>
       <a class="rapids-selector__menu-item" href="/api/cugraph/stable/api.html">
        cugraph
       </a>
       <a class="rapids-selector__menu-item" href="/api/cuml/stable/api.html">
        cuml
       </a>
       <a class="rapids-selector__menu-item" href="/api/cusignal/stable/api.html">
        cusignal
       </a>
       <a class="rapids-selector__menu-item" href="/api/cuspatial/stable/api.html">
        cuspatial
       </a>
       <a class="rapids-selector__menu-item" href="/api/cuxfilter/stable">
        cuxfilter
       </a>
       <a class="rapids-selector__menu-item" href="/api/libcudf/stable/namespacecudf.html">
        libcudf
       </a>
       <a class="rapids-selector__menu-item rapids-selector__menu-item--selected" href="/api/libcuml/nightly">
        libcuml
       </a>
       <a class="rapids-selector__menu-item" href="/api/libnvstrings/stable/annotated.html">
        libnvstrings
       </a>
       <a class="rapids-selector__menu-item" href="/api/nvstrings/stable/api.html">
        nvstrings
       </a>
       <a class="rapids-selector__menu-item" href="/api/rmm/stable/annotated.html">
        rmm
       </a>
      </div>
     </div>
     <div class="rapids-selector__container rapids-selector--hidden">
      <div class="rapids-selector__selected">
       nightly (0.14)
      </div>
      <div class="rapids-selector__menu">
       <a class="rapids-selector__menu-item rapids-selector__menu-item--selected" href="/api/libcuml/nightly">
        nightly (0.14)
       </a>
      </div>
     </div>
    </div>
   </div>
   <!-- end header part -->
   <!-- Generated by Doxygen 1.8.18 -->
   <script type="text/javascript">
    /* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
   </script>
   <script src="menudata.js" type="text/javascript">
   </script>
   <script src="menu.js" type="text/javascript">
   </script>
   <script type="text/javascript">
    /* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
   </script>
   <div id="main-nav">
   </div>
   <!-- window showing the filter options -->
   <div id="MSearchSelectWindow" onkeydown="return searchBox.OnSearchSelectKey(event)" onmouseout="return searchBox.OnSearchSelectHide()" onmouseover="return searchBox.OnSearchSelectShow()">
   </div>
   <!-- iframe showing the search results (closed by default) -->
   <div id="MSearchResultsWindow">
    <iframe frameborder="0" id="MSearchResults" name="MSearchResults" src="javascript:void(0)">
    </iframe>
   </div>
   <div class="navpath" id="nav-path">
    <ul>
     <li class="navelem">
      <a class="el" href="namespaceMLCommon.html">
       MLCommon
      </a>
     </li>
     <li class="navelem">
      <a class="el" href="namespaceMLCommon_1_1Cache.html">
       Cache
      </a>
     </li>
     <li class="navelem">
      <a class="el" href="classMLCommon_1_1Cache_1_1Cache.html">
       Cache
      </a>
     </li>
    </ul>
   </div>
  </div>
  <!-- top -->
  <div class="header">
   <div class="summary">
    <a href="#pub-methods">
     Public Member Functions
    </a>
    |
    <a href="classMLCommon_1_1Cache_1_1Cache-members.html">
     List of all members
    </a>
   </div>
   <div class="headertitle">
    <div class="title">
     MLCommon::Cache::Cache&lt; math_t, associativity &gt; Class Template Reference
    </div>
   </div>
  </div>
  <!--header-->
  <div class="contents">
   <p>
    Associative cache with least recently used replacement policy.
    <a href="classMLCommon_1_1Cache_1_1Cache.html#details">
     More...
    </a>
   </p>
   <p>
    <code>
     #include &lt;
     <a class="el" href="cache_8h_source.html">
      cache.h
     </a>
     &gt;
    </code>
   </p>
   <div class="dynheader">
    Collaboration diagram for MLCommon::Cache::Cache&lt; math_t, associativity &gt;:
   </div>
   <div class="dyncontent">
    <div class="center">
     <img alt="Collaboration graph" border="0" src="classMLCommon_1_1Cache_1_1Cache__coll__graph.png" usemap="#MLCommon_1_1Cache_1_1Cache_3_01math__t_00_01associativity_01_4_coll__map"/>
    </div>
    <map id="MLCommon_1_1Cache_1_1Cache_3_01math__t_00_01associativity_01_4_coll__map" name="MLCommon_1_1Cache_1_1Cache_3_01math__t_00_01associativity_01_4_coll__map">
     <area alt="" coords="5,5,288,229" shape="rect" title="Associative cache with least recently used replacement policy."/>
    </map>
   </div>
   <table class="memberdecls">
    <tr class="heading">
     <td colspan="2">
      <h2 class="groupheader">
       <a name="pub-methods">
       </a>
       Public Member Functions
      </h2>
     </td>
    </tr>
    <tr class="memitem:aa8775f0c6766df8f93d6429793b05c99">
     <td align="right" class="memItemLeft" valign="top">
     </td>
     <td class="memItemRight" valign="bottom">
      <a class="el" href="classMLCommon_1_1Cache_1_1Cache.html#aa8775f0c6766df8f93d6429793b05c99">
       Cache
      </a>
      (std::shared_ptr&lt;
      <a class="el" href="classMLCommon_1_1deviceAllocator.html">
       deviceAllocator
      </a>
      &gt; allocator, cudaStream_t stream, int n_vec, float cache_size=200)
     </td>
    </tr>
    <tr class="memdesc:aa8775f0c6766df8f93d6429793b05c99">
     <td class="mdescLeft">
     </td>
     <td class="mdescRight">
      Construct a
      <a class="el" href="classMLCommon_1_1Cache_1_1Cache.html" title="Associative cache with least recently used replacement policy.">
       Cache
      </a>
      object.
      <a href="classMLCommon_1_1Cache_1_1Cache.html#aa8775f0c6766df8f93d6429793b05c99">
       More...
      </a>
      <br/>
     </td>
    </tr>
    <tr class="separator:aa8775f0c6766df8f93d6429793b05c99">
     <td class="memSeparator" colspan="2">
     </td>
    </tr>
    <tr class="memitem:a3b2a8ccffa9609b81b4006d8c063a640">
     <td align="right" class="memItemLeft" valign="top">
     </td>
     <td class="memItemRight" valign="bottom">
      <a class="el" href="classMLCommon_1_1Cache_1_1Cache.html#a3b2a8ccffa9609b81b4006d8c063a640">
       Cache
      </a>
      (const
      <a class="el" href="classMLCommon_1_1Cache_1_1Cache.html">
       Cache
      </a>
      &amp;other)=delete
     </td>
    </tr>
    <tr class="separator:a3b2a8ccffa9609b81b4006d8c063a640">
     <td class="memSeparator" colspan="2">
     </td>
    </tr>
    <tr class="memitem:ae3fa1d07b3d6e129dfebe9ed0901503f">
     <td align="right" class="memItemLeft" valign="top">
      <a class="el" href="classMLCommon_1_1Cache_1_1Cache.html">
       Cache
      </a>
      &amp;
     </td>
     <td class="memItemRight" valign="bottom">
      <a class="el" href="classMLCommon_1_1Cache_1_1Cache.html#ae3fa1d07b3d6e129dfebe9ed0901503f">
       operator=
      </a>
      (const
      <a class="el" href="classMLCommon_1_1Cache_1_1Cache.html">
       Cache
      </a>
      &amp;other)=delete
     </td>
    </tr>
    <tr class="separator:ae3fa1d07b3d6e129dfebe9ed0901503f">
     <td class="memSeparator" colspan="2">
     </td>
    </tr>
    <tr class="memitem:a028ef37eaa41a24453a55125a52bf8ae">
     <td align="right" class="memItemLeft" valign="top">
      void
     </td>
     <td class="memItemRight" valign="bottom">
      <a class="el" href="classMLCommon_1_1Cache_1_1Cache.html#a028ef37eaa41a24453a55125a52bf8ae">
       GetVecs
      </a>
      (const int *idx, int n, math_t *out, cudaStream_t stream)
     </td>
    </tr>
    <tr class="memdesc:a028ef37eaa41a24453a55125a52bf8ae">
     <td class="mdescLeft">
     </td>
     <td class="mdescRight">
      Collect cached data into contiguous memory space.
      <a href="classMLCommon_1_1Cache_1_1Cache.html#a028ef37eaa41a24453a55125a52bf8ae">
       More...
      </a>
      <br/>
     </td>
    </tr>
    <tr class="separator:a028ef37eaa41a24453a55125a52bf8ae">
     <td class="memSeparator" colspan="2">
     </td>
    </tr>
    <tr class="memitem:ab6d358b2949657482f247b920c021c56">
     <td align="right" class="memItemLeft" valign="top">
      void
     </td>
     <td class="memItemRight" valign="bottom">
      <a class="el" href="classMLCommon_1_1Cache_1_1Cache.html#ab6d358b2949657482f247b920c021c56">
       StoreVecs
      </a>
      (const math_t *tile, int n_tile, int n, int *cache_idx, cudaStream_t stream, const int *tile_idx=nullptr)
     </td>
    </tr>
    <tr class="memdesc:ab6d358b2949657482f247b920c021c56">
     <td class="mdescLeft">
     </td>
     <td class="mdescRight">
      Store vectors of data into the cache.
      <a href="classMLCommon_1_1Cache_1_1Cache.html#ab6d358b2949657482f247b920c021c56">
       More...
      </a>
      <br/>
     </td>
    </tr>
    <tr class="separator:ab6d358b2949657482f247b920c021c56">
     <td class="memSeparator" colspan="2">
     </td>
    </tr>
    <tr class="memitem:aeef597c80b4303cc11223b5c5145d515">
     <td align="right" class="memItemLeft" valign="top">
      void
     </td>
     <td class="memItemRight" valign="bottom">
      <a class="el" href="classMLCommon_1_1Cache_1_1Cache.html#aeef597c80b4303cc11223b5c5145d515">
       GetCacheIdx
      </a>
      (int *keys, int n, int *cache_idx, bool *is_cached, cudaStream_t stream)
     </td>
    </tr>
    <tr class="memdesc:aeef597c80b4303cc11223b5c5145d515">
     <td class="mdescLeft">
     </td>
     <td class="mdescRight">
      Map a set of keys to cache indices.
      <a href="classMLCommon_1_1Cache_1_1Cache.html#aeef597c80b4303cc11223b5c5145d515">
       More...
      </a>
      <br/>
     </td>
    </tr>
    <tr class="separator:aeef597c80b4303cc11223b5c5145d515">
     <td class="memSeparator" colspan="2">
     </td>
    </tr>
    <tr class="memitem:ab3c5ea7e5bac3aca959765083c2c4584">
     <td align="right" class="memItemLeft" valign="top">
      void
     </td>
     <td class="memItemRight" valign="bottom">
      <a class="el" href="classMLCommon_1_1Cache_1_1Cache.html#ab3c5ea7e5bac3aca959765083c2c4584">
       GetCacheIdxPartitioned
      </a>
      (int *keys, int n, int *cache_idx, int *n_cached, cudaStream_t stream)
     </td>
    </tr>
    <tr class="memdesc:ab3c5ea7e5bac3aca959765083c2c4584">
     <td class="mdescLeft">
     </td>
     <td class="mdescRight">
      Map a set of keys to cache indices.
      <a href="classMLCommon_1_1Cache_1_1Cache.html#ab3c5ea7e5bac3aca959765083c2c4584">
       More...
      </a>
      <br/>
     </td>
    </tr>
    <tr class="separator:ab3c5ea7e5bac3aca959765083c2c4584">
     <td class="memSeparator" colspan="2">
     </td>
    </tr>
    <tr class="memitem:adb798e227a65bb6cf979e32f414539ea">
     <td align="right" class="memItemLeft" valign="top">
      void
     </td>
     <td class="memItemRight" valign="bottom">
      <a class="el" href="classMLCommon_1_1Cache_1_1Cache.html#adb798e227a65bb6cf979e32f414539ea">
       AssignCacheIdx
      </a>
      (int *keys, int n, int *cidx, cudaStream_t stream)
     </td>
    </tr>
    <tr class="memdesc:adb798e227a65bb6cf979e32f414539ea">
     <td class="mdescLeft">
     </td>
     <td class="mdescRight">
      Assign cache location to a set of keys.
      <a href="classMLCommon_1_1Cache_1_1Cache.html#adb798e227a65bb6cf979e32f414539ea">
       More...
      </a>
      <br/>
     </td>
    </tr>
    <tr class="separator:adb798e227a65bb6cf979e32f414539ea">
     <td class="memSeparator" colspan="2">
     </td>
    </tr>
    <tr class="memitem:abd4f3b8088cbfa1650231719a82cd49f">
     <td align="right" class="memItemLeft" valign="top">
      float
     </td>
     <td class="memItemRight" valign="bottom">
      <a class="el" href="classMLCommon_1_1Cache_1_1Cache.html#abd4f3b8088cbfa1650231719a82cd49f">
       GetSizeInMiB
      </a>
      () const
     </td>
    </tr>
    <tr class="separator:abd4f3b8088cbfa1650231719a82cd49f">
     <td class="memSeparator" colspan="2">
     </td>
    </tr>
    <tr class="memitem:ab3660a4f40908a9936d476b2e6fecfff">
     <td align="right" class="memItemLeft" valign="top">
      int
     </td>
     <td class="memItemRight" valign="bottom">
      <a class="el" href="classMLCommon_1_1Cache_1_1Cache.html#ab3660a4f40908a9936d476b2e6fecfff">
       GetSize
      </a>
      () const
     </td>
    </tr>
    <tr class="separator:ab3660a4f40908a9936d476b2e6fecfff">
     <td class="memSeparator" colspan="2">
     </td>
    </tr>
   </table>
   <a id="details" name="details">
   </a>
   <h2 class="groupheader">
    Detailed Description
   </h2>
   <div class="textblock">
    <h3>
     template&lt;typename math_t, int associativity = 32&gt;
     <br/>
     class MLCommon::Cache::Cache&lt; math_t, associativity &gt;
    </h3>
    <p>
     Associative cache with least recently used replacement policy.
    </p>
    <p>
     SW managed cache in device memory, for
     <a class="el" href="namespaceML.html">
      ML
     </a>
     algos where we can trade memory access for computation. The two main functions of this class are the management of cache indices, and methods to retrieve/store data using the cache indices.
    </p>
    <p>
     The index management can be considered as a hash map&lt;int, int&gt;, where the int keys are the original vector indices that we want to store, and the values are the cache location of these vectors. The keys are hashed into a bucket whose size equals the associativity. These are the cache sets. If a cache set is full, then new indices are stored by replacing the oldest entries.
    </p>
    <p>
     Using this index mapping we implement methods to store and retrive data from the cache buffer, where a unit of data that we are storing is math_t[n_vec]. For example in SVM we store full columns of the kernel matrix at each cache entry.
    </p>
    <p>
     Note: we should have a look if the index management could be simplified using concurrent_unordered_map.cuh from cudf. See Issue #914.
    </p>
    <p>
     Example usage:
    </p>
    <div class="fragment">
     <div class="line">
      <span class="comment">
       // An expensive calculation that we want to accelerate with caching:
      </span>
     </div>
     <div class="line">
      <span class="comment">
       // we have n keys, and for each key we generate a vector with m elements.
      </span>
     </div>
     <div class="line">
      <span class="comment">
       // The keys and the output values are stored in GPU memory.
      </span>
     </div>
     <div class="line">
      <span class="keywordtype">
       void
      </span>
      calc(
      <span class="keywordtype">
       int
      </span>
      *key,
      <span class="keywordtype">
       int
      </span>
      <a class="code" href="namespaceML_1_1TSNE.html#a1cd86a623f64db84ca537da23b68223c">
       n
      </a>
      ,
      <span class="keywordtype">
       int
      </span>
      <a class="code" href="namespaceMLCommon_1_1Distance.html#a2424d27a67d0483530b531f6ac12d07f">
       m
      </a>
      ,
      <span class="keywordtype">
       float
      </span>
      *out, cudaStream_t stream) {
     </div>
     <div class="line">
      <span class="keywordflow">
       for
      </span>
      (
      <a class="code" href="namespaceML_1_1TSNE.html#afb851e919e0cd78a7c66faf65d407452">
       k
      </a>
      =0;
      <a class="code" href="namespaceML_1_1TSNE.html#afb851e919e0cd78a7c66faf65d407452">
       k
      </a>
      &lt;
      <a class="code" href="namespaceML_1_1TSNE.html#a1cd86a623f64db84ca537da23b68223c">
       n
      </a>
      ;
      <a class="code" href="namespaceML_1_1TSNE.html#afb851e919e0cd78a7c66faf65d407452">
       k
      </a>
      ++) {
     </div>
     <div class="line">
      <span class="comment">
       // use key[k] to generate out[i + m*k],  where i=0..m-1
      </span>
     </div>
     <div class="line">
      }
     </div>
     <div class="line">
      }
     </div>
     <div class="line">
     </div>
     <div class="line">
      <span class="comment">
       // We assume that our ML algo repeatedly calls calc, and the set of keys have
      </span>
     </div>
     <div class="line">
      <span class="comment">
       // an overlap. We will use the cache to avoid repeated calculations.
      </span>
     </div>
     <div class="line">
     </div>
     <div class="line">
      <span class="comment">
       // Assume we have cumlHandle_impl&amp; h, and cudaStream_t stream
      </span>
     </div>
     <div class="line">
      Cache&lt;float&gt; cache(h.getDeviceAllocator(), stream,
      <a class="code" href="namespaceMLCommon_1_1Distance.html#a2424d27a67d0483530b531f6ac12d07f">
       m
      </a>
      );
     </div>
     <div class="line">
     </div>
     <div class="line">
      <span class="comment">
       // A buffer that we will reuse to store the cache indices.
      </span>
     </div>
     <div class="line">
      device_buffer&lt;int&gt; cache_idx(h.getDeviceAllocator(), stream,
      <a class="code" href="namespaceML_1_1TSNE.html#a1cd86a623f64db84ca537da23b68223c">
       n
      </a>
      );
     </div>
     <div class="line">
     </div>
     <div class="line">
      <span class="keywordtype">
       void
      </span>
      cached_calc(
      <span class="keywordtype">
       int
      </span>
      *key,
      <span class="keywordtype">
       int
      </span>
      <a class="code" href="namespaceML_1_1TSNE.html#a1cd86a623f64db84ca537da23b68223c">
       n
      </a>
      ,
      <span class="keywordtype">
       int
      </span>
      <a class="code" href="namespaceMLCommon_1_1Distance.html#a2424d27a67d0483530b531f6ac12d07f">
       m
      </a>
      ,
      <span class="keywordtype">
       float
      </span>
      *out, stream) {
     </div>
     <div class="line">
      <span class="keywordtype">
       int
      </span>
      n_cached = 0;
     </div>
     <div class="line">
     </div>
     <div class="line">
      cache.GetCacheIdxPartitioned(key,
      <a class="code" href="namespaceML_1_1TSNE.html#a1cd86a623f64db84ca537da23b68223c">
       n
      </a>
      , cache_idx.data(), &amp;n_cached,
     </div>
     <div class="line">
      cudaStream_t stream);
     </div>
     <div class="line">
     </div>
     <div class="line">
      <span class="comment">
       // Note: GetCacheIdxPartitioned has reordered the keys so that
      </span>
     </div>
     <div class="line">
      <span class="comment">
       // key[0..n_cached-1] are the keys already in the cache.
      </span>
     </div>
     <div class="line">
      <span class="comment">
       // We collect the corresponding values
      </span>
     </div>
     <div class="line">
      cache.GetVecs(cache_idx.data(), n_cached, out, stream);
     </div>
     <div class="line">
     </div>
     <div class="line">
      <span class="comment">
       // Calculate the elements not in the cache
      </span>
     </div>
     <div class="line">
      <span class="keywordtype">
       int
      </span>
      non_cached =
      <a class="code" href="namespaceML_1_1TSNE.html#a1cd86a623f64db84ca537da23b68223c">
       n
      </a>
      - n_cached;
     </div>
     <div class="line">
      <span class="keywordflow">
       if
      </span>
      (non_cached &gt; 0) {
     </div>
     <div class="line">
      <span class="keywordtype">
       int
      </span>
      *key_new = key + n_cached;
     </div>
     <div class="line">
      <span class="keywordtype">
       int
      </span>
      *cache_idx_new = cache_idx.data() + n_cached;
     </div>
     <div class="line">
      <span class="keywordtype">
       float
      </span>
      *out_new = out + n_cached *
      <a class="code" href="namespaceMLCommon_1_1Distance.html#a2424d27a67d0483530b531f6ac12d07f">
       m
      </a>
      ;
     </div>
     <div class="line">
      <span class="comment">
       // AssignCacheIdx can permute the keys, therefore it has to come before
      </span>
     </div>
     <div class="line">
      <span class="comment">
       // we call calc.
      </span>
     </div>
     <div class="line">
      <span class="comment">
       // Note: a call to AssignCacheIdx should always be preceded with
      </span>
     </div>
     <div class="line">
      <span class="comment">
       // GetCacheIdxPartitioned, because that initializes the cache_idx_new array
      </span>
     </div>
     <div class="line">
      <span class="comment">
       // with the cache set (hash bucket) that correspond to the keys.
      </span>
     </div>
     <div class="line">
      <span class="comment">
       // The cache idx will be assigned from that cache set.
      </span>
     </div>
     <div class="line">
      cache.AssignCacheIdx(key_new, non_cached, cache_idx_new, stream);
     </div>
     <div class="line">
     </div>
     <div class="line">
      calc(key_new, non_cached,
      <a class="code" href="namespaceMLCommon_1_1Distance.html#a2424d27a67d0483530b531f6ac12d07f">
       m
      </a>
      , out_new, stream);
     </div>
     <div class="line">
     </div>
     <div class="line">
      <span class="comment">
       // Store the calculated vectors into the cache.
      </span>
     </div>
     <div class="line">
      cache.StoreVecs(out_new, non_cached, non_cached, cache_idx_new, stream);
     </div>
     <div class="line">
      }
     </div>
     <div class="line">
      }
     </div>
    </div>
    <!-- fragment -->
   </div>
   <h2 class="groupheader">
    Constructor &amp; Destructor Documentation
   </h2>
   <a id="aa8775f0c6766df8f93d6429793b05c99">
   </a>
   <h2 class="memtitle">
    <span class="permalink">
     <a href="#aa8775f0c6766df8f93d6429793b05c99">
      ◆
     </a>
    </span>
    Cache()
    <span class="overload">
     [1/2]
    </span>
   </h2>
   <div class="memitem">
    <div class="memproto">
     <div class="memtemplate">
      template&lt;typename math_t , int associativity = 32&gt;
     </div>
     <table class="mlabels">
      <tr>
       <td class="mlabels-left">
        <table class="memname">
         <tr>
          <td class="memname">
           <a class="el" href="classMLCommon_1_1Cache_1_1Cache.html">
            MLCommon::Cache::Cache
           </a>
           &lt; math_t, associativity &gt;::
           <a class="el" href="classMLCommon_1_1Cache_1_1Cache.html">
            Cache
           </a>
          </td>
          <td>
           (
          </td>
          <td class="paramtype">
           std::shared_ptr&lt;
           <a class="el" href="classMLCommon_1_1deviceAllocator.html">
            deviceAllocator
           </a>
           &gt;
          </td>
          <td class="paramname">
           <em>
            allocator
           </em>
           ,
          </td>
         </tr>
         <tr>
          <td class="paramkey">
          </td>
          <td>
          </td>
          <td class="paramtype">
           cudaStream_t
          </td>
          <td class="paramname">
           <em>
            stream
           </em>
           ,
          </td>
         </tr>
         <tr>
          <td class="paramkey">
          </td>
          <td>
          </td>
          <td class="paramtype">
           int
          </td>
          <td class="paramname">
           <em>
            n_vec
           </em>
           ,
          </td>
         </tr>
         <tr>
          <td class="paramkey">
          </td>
          <td>
          </td>
          <td class="paramtype">
           float
          </td>
          <td class="paramname">
           <em>
            cache_size
           </em>
           =
           <code>
            200
           </code>
          </td>
         </tr>
         <tr>
          <td>
          </td>
          <td>
           )
          </td>
          <td>
          </td>
          <td>
          </td>
         </tr>
        </table>
       </td>
       <td class="mlabels-right">
        <span class="mlabels">
         <span class="mlabel">
          inline
         </span>
        </span>
       </td>
      </tr>
     </table>
    </div>
    <div class="memdoc">
     <p>
      Construct a
      <a class="el" href="classMLCommon_1_1Cache_1_1Cache.html" title="Associative cache with least recently used replacement policy.">
       Cache
      </a>
      object.
     </p>
     <dl class="tparams">
      <dt>
       Template Parameters
      </dt>
      <dd>
       <table class="tparams">
        <tr>
         <td class="paramname">
          math_t
         </td>
         <td>
          type of elements to be cached
         </td>
        </tr>
        <tr>
         <td class="paramname">
          associativity
         </td>
         <td>
          number of vectors in a cache set
         </td>
        </tr>
       </table>
      </dd>
     </dl>
     <dl class="params">
      <dt>
       Parameters
      </dt>
      <dd>
       <table class="params">
        <tr>
         <td class="paramname">
          allocator
         </td>
         <td>
          device memory allocator
         </td>
        </tr>
        <tr>
         <td class="paramname">
          stream
         </td>
         <td>
          cuda stream
         </td>
        </tr>
        <tr>
         <td class="paramname">
          n_vec
         </td>
         <td>
          number of elements in a single vector that is stored in a cache entry
         </td>
        </tr>
        <tr>
         <td class="paramname">
          cache_size
         </td>
         <td>
          in MiB
         </td>
        </tr>
       </table>
      </dd>
     </dl>
    </div>
   </div>
   <a id="a3b2a8ccffa9609b81b4006d8c063a640">
   </a>
   <h2 class="memtitle">
    <span class="permalink">
     <a href="#a3b2a8ccffa9609b81b4006d8c063a640">
      ◆
     </a>
    </span>
    Cache()
    <span class="overload">
     [2/2]
    </span>
   </h2>
   <div class="memitem">
    <div class="memproto">
     <div class="memtemplate">
      template&lt;typename math_t , int associativity = 32&gt;
     </div>
     <table class="mlabels">
      <tr>
       <td class="mlabels-left">
        <table class="memname">
         <tr>
          <td class="memname">
           <a class="el" href="classMLCommon_1_1Cache_1_1Cache.html">
            MLCommon::Cache::Cache
           </a>
           &lt; math_t, associativity &gt;::
           <a class="el" href="classMLCommon_1_1Cache_1_1Cache.html">
            Cache
           </a>
          </td>
          <td>
           (
          </td>
          <td class="paramtype">
           const
           <a class="el" href="classMLCommon_1_1Cache_1_1Cache.html">
            Cache
           </a>
           &lt; math_t, associativity &gt; &amp;
          </td>
          <td class="paramname">
           <em>
            other
           </em>
          </td>
          <td>
           )
          </td>
          <td>
          </td>
         </tr>
        </table>
       </td>
       <td class="mlabels-right">
        <span class="mlabels">
         <span class="mlabel">
          delete
         </span>
        </span>
       </td>
      </tr>
     </table>
    </div>
    <div class="memdoc">
    </div>
   </div>
   <h2 class="groupheader">
    Member Function Documentation
   </h2>
   <a id="adb798e227a65bb6cf979e32f414539ea">
   </a>
   <h2 class="memtitle">
    <span class="permalink">
     <a href="#adb798e227a65bb6cf979e32f414539ea">
      ◆
     </a>
    </span>
    AssignCacheIdx()
   </h2>
   <div class="memitem">
    <div class="memproto">
     <div class="memtemplate">
      template&lt;typename math_t , int associativity = 32&gt;
     </div>
     <table class="mlabels">
      <tr>
       <td class="mlabels-left">
        <table class="memname">
         <tr>
          <td class="memname">
           void
           <a class="el" href="classMLCommon_1_1Cache_1_1Cache.html">
            MLCommon::Cache::Cache
           </a>
           &lt; math_t, associativity &gt;::AssignCacheIdx
          </td>
          <td>
           (
          </td>
          <td class="paramtype">
           int *
          </td>
          <td class="paramname">
           <em>
            keys
           </em>
           ,
          </td>
         </tr>
         <tr>
          <td class="paramkey">
          </td>
          <td>
          </td>
          <td class="paramtype">
           int
          </td>
          <td class="paramname">
           <em>
            n
           </em>
           ,
          </td>
         </tr>
         <tr>
          <td class="paramkey">
          </td>
          <td>
          </td>
          <td class="paramtype">
           int *
          </td>
          <td class="paramname">
           <em>
            cidx
           </em>
           ,
          </td>
         </tr>
         <tr>
          <td class="paramkey">
          </td>
          <td>
          </td>
          <td class="paramtype">
           cudaStream_t
          </td>
          <td class="paramname">
           <em>
            stream
           </em>
          </td>
         </tr>
         <tr>
          <td>
          </td>
          <td>
           )
          </td>
          <td>
          </td>
          <td>
          </td>
         </tr>
        </table>
       </td>
       <td class="mlabels-right">
        <span class="mlabels">
         <span class="mlabel">
          inline
         </span>
        </span>
       </td>
      </tr>
     </table>
    </div>
    <div class="memdoc">
     <p>
      Assign cache location to a set of keys.
     </p>
     <p>
      Note: call GetCacheIdx first, to get the cache_set assigned to the keys. Keys that cannot be cached are assigned to -1.
     </p>
     <dl class="params">
      <dt>
       Parameters
      </dt>
      <dd>
       <table class="params">
        <tr>
         <td class="paramdir">
          [in,out]
         </td>
         <td class="paramname">
          keys
         </td>
         <td>
          device array of keys, size [n]
         </td>
        </tr>
        <tr>
         <td class="paramdir">
          [in]
         </td>
         <td class="paramname">
          n
         </td>
         <td>
          number of elements that we want to cache
         </td>
        </tr>
        <tr>
         <td class="paramdir">
          [in,out]
         </td>
         <td class="paramname">
          cidx
         </td>
         <td>
          on entry: cache_set, on exit: assigned cache_idx or -1, size[n]
         </td>
        </tr>
        <tr>
         <td class="paramdir">
          [in]
         </td>
         <td class="paramname">
          stream
         </td>
         <td>
          cuda stream
         </td>
        </tr>
       </table>
      </dd>
     </dl>
    </div>
   </div>
   <a id="aeef597c80b4303cc11223b5c5145d515">
   </a>
   <h2 class="memtitle">
    <span class="permalink">
     <a href="#aeef597c80b4303cc11223b5c5145d515">
      ◆
     </a>
    </span>
    GetCacheIdx()
   </h2>
   <div class="memitem">
    <div class="memproto">
     <div class="memtemplate">
      template&lt;typename math_t , int associativity = 32&gt;
     </div>
     <table class="mlabels">
      <tr>
       <td class="mlabels-left">
        <table class="memname">
         <tr>
          <td class="memname">
           void
           <a class="el" href="classMLCommon_1_1Cache_1_1Cache.html">
            MLCommon::Cache::Cache
           </a>
           &lt; math_t, associativity &gt;::GetCacheIdx
          </td>
          <td>
           (
          </td>
          <td class="paramtype">
           int *
          </td>
          <td class="paramname">
           <em>
            keys
           </em>
           ,
          </td>
         </tr>
         <tr>
          <td class="paramkey">
          </td>
          <td>
          </td>
          <td class="paramtype">
           int
          </td>
          <td class="paramname">
           <em>
            n
           </em>
           ,
          </td>
         </tr>
         <tr>
          <td class="paramkey">
          </td>
          <td>
          </td>
          <td class="paramtype">
           int *
          </td>
          <td class="paramname">
           <em>
            cache_idx
           </em>
           ,
          </td>
         </tr>
         <tr>
          <td class="paramkey">
          </td>
          <td>
          </td>
          <td class="paramtype">
           bool *
          </td>
          <td class="paramname">
           <em>
            is_cached
           </em>
           ,
          </td>
         </tr>
         <tr>
          <td class="paramkey">
          </td>
          <td>
          </td>
          <td class="paramtype">
           cudaStream_t
          </td>
          <td class="paramname">
           <em>
            stream
           </em>
          </td>
         </tr>
         <tr>
          <td>
          </td>
          <td>
           )
          </td>
          <td>
          </td>
          <td>
          </td>
         </tr>
        </table>
       </td>
       <td class="mlabels-right">
        <span class="mlabels">
         <span class="mlabel">
          inline
         </span>
        </span>
       </td>
      </tr>
     </table>
    </div>
    <div class="memdoc">
     <p>
      Map a set of keys to cache indices.
     </p>
     <p>
      For each k in 0..n-1, if keys[k] is found in the cache, then cache_idx[k] will tell the corresponding cache idx, and is_cached[k] is set to true.
     </p>
     <p>
      If keys[k] is not found in the cache, then is_cached[k] is set to false. In this case we assign the cache set for keys[k], and cache_idx[k] will store the cache set.
     </p>
     <dl class="section note">
      <dt>
       Note
      </dt>
      <dd>
       in order to retrieve the cached vector j=cache_idx[k] from the cache, we have to access cache[i + j*n_vec], where i=0..n_vec-1.
      </dd>
      <dd>
       : do not use simultaneous GetCacheIdx and AssignCacheIdx
      </dd>
     </dl>
     <dl class="params">
      <dt>
       Parameters
      </dt>
      <dd>
       <table class="params">
        <tr>
         <td class="paramdir">
          [in]
         </td>
         <td class="paramname">
          keys
         </td>
         <td>
          device array of keys, size [n]
         </td>
        </tr>
        <tr>
         <td class="paramdir">
          [in]
         </td>
         <td class="paramname">
          n
         </td>
         <td>
          number of keys
         </td>
        </tr>
        <tr>
         <td class="paramdir">
          [out]
         </td>
         <td class="paramname">
          cache_idx
         </td>
         <td>
          device array of cache indices corresponding to the input keys, size [n]
         </td>
        </tr>
        <tr>
         <td class="paramdir">
          [out]
         </td>
         <td class="paramname">
          is_cached
         </td>
         <td>
          whether the element is already available in the cache, size [n]
         </td>
        </tr>
        <tr>
         <td class="paramdir">
          [in]
         </td>
         <td class="paramname">
          stream
         </td>
         <td>
         </td>
        </tr>
       </table>
      </dd>
     </dl>
    </div>
   </div>
   <a id="ab3c5ea7e5bac3aca959765083c2c4584">
   </a>
   <h2 class="memtitle">
    <span class="permalink">
     <a href="#ab3c5ea7e5bac3aca959765083c2c4584">
      ◆
     </a>
    </span>
    GetCacheIdxPartitioned()
   </h2>
   <div class="memitem">
    <div class="memproto">
     <div class="memtemplate">
      template&lt;typename math_t , int associativity = 32&gt;
     </div>
     <table class="mlabels">
      <tr>
       <td class="mlabels-left">
        <table class="memname">
         <tr>
          <td class="memname">
           void
           <a class="el" href="classMLCommon_1_1Cache_1_1Cache.html">
            MLCommon::Cache::Cache
           </a>
           &lt; math_t, associativity &gt;::GetCacheIdxPartitioned
          </td>
          <td>
           (
          </td>
          <td class="paramtype">
           int *
          </td>
          <td class="paramname">
           <em>
            keys
           </em>
           ,
          </td>
         </tr>
         <tr>
          <td class="paramkey">
          </td>
          <td>
          </td>
          <td class="paramtype">
           int
          </td>
          <td class="paramname">
           <em>
            n
           </em>
           ,
          </td>
         </tr>
         <tr>
          <td class="paramkey">
          </td>
          <td>
          </td>
          <td class="paramtype">
           int *
          </td>
          <td class="paramname">
           <em>
            cache_idx
           </em>
           ,
          </td>
         </tr>
         <tr>
          <td class="paramkey">
          </td>
          <td>
          </td>
          <td class="paramtype">
           int *
          </td>
          <td class="paramname">
           <em>
            n_cached
           </em>
           ,
          </td>
         </tr>
         <tr>
          <td class="paramkey">
          </td>
          <td>
          </td>
          <td class="paramtype">
           cudaStream_t
          </td>
          <td class="paramname">
           <em>
            stream
           </em>
          </td>
         </tr>
         <tr>
          <td>
          </td>
          <td>
           )
          </td>
          <td>
          </td>
          <td>
          </td>
         </tr>
        </table>
       </td>
       <td class="mlabels-right">
        <span class="mlabels">
         <span class="mlabel">
          inline
         </span>
        </span>
       </td>
      </tr>
     </table>
    </div>
    <div class="memdoc">
     <p>
      Map a set of keys to cache indices.
     </p>
     <p>
      Same as GetCacheIdx, but partitions the keys, and cache_idx arrays in a way that keys[0..n_cached-1] and cache_idx[0..n_cached-1] store the indices of vectors that are found in the cache, while keys[n_cached..n-1] are the indices of vectors that are not found in the cache. For the vectors not found in the cache, cache_idx[n_cached..n-1] stores the cache set, and this can be used to call AssignCacheIdx.
     </p>
     <dl class="params">
      <dt>
       Parameters
      </dt>
      <dd>
       <table class="params">
        <tr>
         <td class="paramdir">
          [in,out]
         </td>
         <td class="paramname">
          keys
         </td>
         <td>
          device array of keys, size [n]
         </td>
        </tr>
        <tr>
         <td class="paramdir">
          [in]
         </td>
         <td class="paramname">
          n
         </td>
         <td>
          number of indices
         </td>
        </tr>
        <tr>
         <td class="paramdir">
          [out]
         </td>
         <td class="paramname">
          cache_idx
         </td>
         <td>
          device array of cache indices corresponding to the input keys, size [n]
         </td>
        </tr>
        <tr>
         <td class="paramdir">
          [out]
         </td>
         <td class="paramname">
          n_cached
         </td>
         <td>
          number of elements that are cached
         </td>
        </tr>
        <tr>
         <td class="paramdir">
          [in]
         </td>
         <td class="paramname">
          stream
         </td>
         <td>
          cuda stream
         </td>
        </tr>
       </table>
      </dd>
     </dl>
    </div>
   </div>
   <a id="ab3660a4f40908a9936d476b2e6fecfff">
   </a>
   <h2 class="memtitle">
    <span class="permalink">
     <a href="#ab3660a4f40908a9936d476b2e6fecfff">
      ◆
     </a>
    </span>
    GetSize()
   </h2>
   <div class="memitem">
    <div class="memproto">
     <div class="memtemplate">
      template&lt;typename math_t , int associativity = 32&gt;
     </div>
     <table class="mlabels">
      <tr>
       <td class="mlabels-left">
        <table class="memname">
         <tr>
          <td class="memname">
           int
           <a class="el" href="classMLCommon_1_1Cache_1_1Cache.html">
            MLCommon::Cache::Cache
           </a>
           &lt; math_t, associativity &gt;::GetSize
          </td>
          <td>
           (
          </td>
          <td class="paramname">
          </td>
          <td>
           )
          </td>
          <td>
           const
          </td>
         </tr>
        </table>
       </td>
       <td class="mlabels-right">
        <span class="mlabels">
         <span class="mlabel">
          inline
         </span>
        </span>
       </td>
      </tr>
     </table>
    </div>
    <div class="memdoc">
     <p>
      Returns the number of vectors that can be cached.
     </p>
    </div>
   </div>
   <a id="abd4f3b8088cbfa1650231719a82cd49f">
   </a>
   <h2 class="memtitle">
    <span class="permalink">
     <a href="#abd4f3b8088cbfa1650231719a82cd49f">
      ◆
     </a>
    </span>
    GetSizeInMiB()
   </h2>
   <div class="memitem">
    <div class="memproto">
     <div class="memtemplate">
      template&lt;typename math_t , int associativity = 32&gt;
     </div>
     <table class="mlabels">
      <tr>
       <td class="mlabels-left">
        <table class="memname">
         <tr>
          <td class="memname">
           float
           <a class="el" href="classMLCommon_1_1Cache_1_1Cache.html">
            MLCommon::Cache::Cache
           </a>
           &lt; math_t, associativity &gt;::GetSizeInMiB
          </td>
          <td>
           (
          </td>
          <td class="paramname">
          </td>
          <td>
           )
          </td>
          <td>
           const
          </td>
         </tr>
        </table>
       </td>
       <td class="mlabels-right">
        <span class="mlabels">
         <span class="mlabel">
          inline
         </span>
        </span>
       </td>
      </tr>
     </table>
    </div>
    <div class="memdoc">
     <p>
      Return approximate cache size in MiB.
     </p>
    </div>
   </div>
   <a id="a028ef37eaa41a24453a55125a52bf8ae">
   </a>
   <h2 class="memtitle">
    <span class="permalink">
     <a href="#a028ef37eaa41a24453a55125a52bf8ae">
      ◆
     </a>
    </span>
    GetVecs()
   </h2>
   <div class="memitem">
    <div class="memproto">
     <div class="memtemplate">
      template&lt;typename math_t , int associativity = 32&gt;
     </div>
     <table class="mlabels">
      <tr>
       <td class="mlabels-left">
        <table class="memname">
         <tr>
          <td class="memname">
           void
           <a class="el" href="classMLCommon_1_1Cache_1_1Cache.html">
            MLCommon::Cache::Cache
           </a>
           &lt; math_t, associativity &gt;::GetVecs
          </td>
          <td>
           (
          </td>
          <td class="paramtype">
           const int *
          </td>
          <td class="paramname">
           <em>
            idx
           </em>
           ,
          </td>
         </tr>
         <tr>
          <td class="paramkey">
          </td>
          <td>
          </td>
          <td class="paramtype">
           int
          </td>
          <td class="paramname">
           <em>
            n
           </em>
           ,
          </td>
         </tr>
         <tr>
          <td class="paramkey">
          </td>
          <td>
          </td>
          <td class="paramtype">
           math_t *
          </td>
          <td class="paramname">
           <em>
            out
           </em>
           ,
          </td>
         </tr>
         <tr>
          <td class="paramkey">
          </td>
          <td>
          </td>
          <td class="paramtype">
           cudaStream_t
          </td>
          <td class="paramname">
           <em>
            stream
           </em>
          </td>
         </tr>
         <tr>
          <td>
          </td>
          <td>
           )
          </td>
          <td>
          </td>
          <td>
          </td>
         </tr>
        </table>
       </td>
       <td class="mlabels-right">
        <span class="mlabels">
         <span class="mlabel">
          inline
         </span>
        </span>
       </td>
      </tr>
     </table>
    </div>
    <div class="memdoc">
     <p>
      Collect cached data into contiguous memory space.
     </p>
     <p>
      On exit, the tile array is filled the following way: out[i + n_vec*k] = cache[i + n_vec * idx[k]]), where i=0..n_vec-1, k = 0..n-1
     </p>
     <p>
      Idx values less than 0 are ignored.
     </p>
     <dl class="params">
      <dt>
       Parameters
      </dt>
      <dd>
       <table class="params">
        <tr>
         <td class="paramdir">
          [in]
         </td>
         <td class="paramname">
          idx
         </td>
         <td>
          cache indices, size [n]
         </td>
        </tr>
        <tr>
         <td class="paramdir">
          [in]
         </td>
         <td class="paramname">
          n
         </td>
         <td>
          the number of vectors that need to be collected
         </td>
        </tr>
        <tr>
         <td class="paramdir">
          [out]
         </td>
         <td class="paramname">
          out
         </td>
         <td>
          vectors collected from cache, size [n_vec*n]
         </td>
        </tr>
        <tr>
         <td class="paramdir">
          [in]
         </td>
         <td class="paramname">
          stream
         </td>
         <td>
          cuda stream
         </td>
        </tr>
       </table>
      </dd>
     </dl>
    </div>
   </div>
   <a id="ae3fa1d07b3d6e129dfebe9ed0901503f">
   </a>
   <h2 class="memtitle">
    <span class="permalink">
     <a href="#ae3fa1d07b3d6e129dfebe9ed0901503f">
      ◆
     </a>
    </span>
    operator=()
   </h2>
   <div class="memitem">
    <div class="memproto">
     <div class="memtemplate">
      template&lt;typename math_t , int associativity = 32&gt;
     </div>
     <table class="mlabels">
      <tr>
       <td class="mlabels-left">
        <table class="memname">
         <tr>
          <td class="memname">
           <a class="el" href="classMLCommon_1_1Cache_1_1Cache.html">
            Cache
           </a>
           &amp;
           <a class="el" href="classMLCommon_1_1Cache_1_1Cache.html">
            MLCommon::Cache::Cache
           </a>
           &lt; math_t, associativity &gt;::operator=
          </td>
          <td>
           (
          </td>
          <td class="paramtype">
           const
           <a class="el" href="classMLCommon_1_1Cache_1_1Cache.html">
            Cache
           </a>
           &lt; math_t, associativity &gt; &amp;
          </td>
          <td class="paramname">
           <em>
            other
           </em>
          </td>
          <td>
           )
          </td>
          <td>
          </td>
         </tr>
        </table>
       </td>
       <td class="mlabels-right">
        <span class="mlabels">
         <span class="mlabel">
          delete
         </span>
        </span>
       </td>
      </tr>
     </table>
    </div>
    <div class="memdoc">
    </div>
   </div>
   <a id="ab6d358b2949657482f247b920c021c56">
   </a>
   <h2 class="memtitle">
    <span class="permalink">
     <a href="#ab6d358b2949657482f247b920c021c56">
      ◆
     </a>
    </span>
    StoreVecs()
   </h2>
   <div class="memitem">
    <div class="memproto">
     <div class="memtemplate">
      template&lt;typename math_t , int associativity = 32&gt;
     </div>
     <table class="mlabels">
      <tr>
       <td class="mlabels-left">
        <table class="memname">
         <tr>
          <td class="memname">
           void
           <a class="el" href="classMLCommon_1_1Cache_1_1Cache.html">
            MLCommon::Cache::Cache
           </a>
           &lt; math_t, associativity &gt;::StoreVecs
          </td>
          <td>
           (
          </td>
          <td class="paramtype">
           const math_t *
          </td>
          <td class="paramname">
           <em>
            tile
           </em>
           ,
          </td>
         </tr>
         <tr>
          <td class="paramkey">
          </td>
          <td>
          </td>
          <td class="paramtype">
           int
          </td>
          <td class="paramname">
           <em>
            n_tile
           </em>
           ,
          </td>
         </tr>
         <tr>
          <td class="paramkey">
          </td>
          <td>
          </td>
          <td class="paramtype">
           int
          </td>
          <td class="paramname">
           <em>
            n
           </em>
           ,
          </td>
         </tr>
         <tr>
          <td class="paramkey">
          </td>
          <td>
          </td>
          <td class="paramtype">
           int *
          </td>
          <td class="paramname">
           <em>
            cache_idx
           </em>
           ,
          </td>
         </tr>
         <tr>
          <td class="paramkey">
          </td>
          <td>
          </td>
          <td class="paramtype">
           cudaStream_t
          </td>
          <td class="paramname">
           <em>
            stream
           </em>
           ,
          </td>
         </tr>
         <tr>
          <td class="paramkey">
          </td>
          <td>
          </td>
          <td class="paramtype">
           const int *
          </td>
          <td class="paramname">
           <em>
            tile_idx
           </em>
           =
           <code>
            nullptr
           </code>
          </td>
         </tr>
         <tr>
          <td>
          </td>
          <td>
           )
          </td>
          <td>
          </td>
          <td>
          </td>
         </tr>
        </table>
       </td>
       <td class="mlabels-right">
        <span class="mlabels">
         <span class="mlabel">
          inline
         </span>
        </span>
       </td>
      </tr>
     </table>
    </div>
    <div class="memdoc">
     <p>
      Store vectors of data into the cache.
     </p>
     <p>
      Roughly the opposite of GetVecs, but the input vectors can be scattered in memory. The cache is updated using the following formula:
     </p>
     <p>
      cache[i + cache_idx[k]*n_vec] = tile[i + tile_idx[k]*n_vec], for i=0..n_vec-1, k=0..n-1
     </p>
     <p>
      If tile_idx==nullptr, then we assume tile_idx[k] = k.
     </p>
     <p>
      Elements within a vector should be contiguous in memory (i.e. column vectors for column major data storage, or row vectors of row major data).
     </p>
     <dl class="params">
      <dt>
       Parameters
      </dt>
      <dd>
       <table class="params">
        <tr>
         <td class="paramdir">
          [in]
         </td>
         <td class="paramname">
          tile
         </td>
         <td>
          stores the data to be cashed cached, size [n_vec x n_tile]
         </td>
        </tr>
        <tr>
         <td class="paramdir">
          [in]
         </td>
         <td class="paramname">
          n_tile
         </td>
         <td>
          number of vectors in tile (at least n)
         </td>
        </tr>
        <tr>
         <td class="paramdir">
          [in]
         </td>
         <td class="paramname">
          n
         </td>
         <td>
          number of vectors that need to be stored in the cache (a subset of all the vectors in the tile)
         </td>
        </tr>
        <tr>
         <td class="paramdir">
          [in]
         </td>
         <td class="paramname">
          cache_idx
         </td>
         <td>
          cache indices for storing the vectors (negative values are ignored), size [n]
         </td>
        </tr>
        <tr>
         <td class="paramdir">
          [in]
         </td>
         <td class="paramname">
          stream
         </td>
         <td>
          cuda stream
         </td>
        </tr>
        <tr>
         <td class="paramdir">
          [in]
         </td>
         <td class="paramname">
          tile_idx
         </td>
         <td>
          indices of vectors that need to be stored
         </td>
        </tr>
       </table>
      </dd>
     </dl>
    </div>
   </div>
   <hr/>
   The documentation for this class was generated from the following file:
   <ul>
    <li>
     /rapids/cuml/cpp/src_prims/cache/
     <a class="el" href="cache_8h_source.html">
      cache.h
     </a>
    </li>
   </ul>
  </div>
  <!-- contents -->
  <div class="ttc" id="anamespaceML_1_1TSNE_html_a1cd86a623f64db84ca537da23b68223c">
   <div class="ttname">
    <a href="namespaceML_1_1TSNE.html#a1cd86a623f64db84ca537da23b68223c">
     ML::TSNE::n
    </a>
   </div>
   <div class="ttdeci">
    int n
   </div>
   <div class="ttdef">
    <b>
     Definition:
    </b>
    bh_kernels.h:188
   </div>
  </div>
  <div class="ttc" id="anamespaceML_1_1TSNE_html_afb851e919e0cd78a7c66faf65d407452">
   <div class="ttname">
    <a href="namespaceML_1_1TSNE.html#afb851e919e0cd78a7c66faf65d407452">
     ML::TSNE::k
    </a>
   </div>
   <div class="ttdeci">
    int k
   </div>
   <div class="ttdef">
    <b>
     Definition:
    </b>
    bh_kernels.h:165
   </div>
  </div>
  <div class="ttc" id="anamespaceMLCommon_1_1Distance_html_a2424d27a67d0483530b531f6ac12d07f">
   <div class="ttname">
    <a href="namespaceMLCommon_1_1Distance.html#a2424d27a67d0483530b531f6ac12d07f">
     MLCommon::Distance::m
    </a>
   </div>
   <div class="ttdeci">
    __global__ const DataT const DataT const DataT const DataT IdxT m
   </div>
   <div class="ttdef">
    <b>
     Definition:
    </b>
    fused_l2_nn.h:263
   </div>
  </div>
  <!-- start footer part -->
  <hr class="footer"/>
  <address class="footer">
   <small>
    Generated by
    <a href="http://www.doxygen.org/index.html">
     <img alt="doxygen" class="footer" src="doxygen.png"/>
    </a>
    1.8.18
   </small>
  </address>
  <script defer id="rapids-selector-js" src="/assets/js/custom.js">
  </script>
 </body>
</html>
