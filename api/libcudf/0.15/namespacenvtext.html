<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta content="text/xhtml;charset=utf-8" http-equiv="Content-Type"/>
<meta content="IE=9" http-equiv="X-UA-Compatible"/>
<meta content="Doxygen 1.8.18" name="generator"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<title>libcudf: nvtext Namespace Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script src="jquery.js" type="text/javascript"></script>
<script src="dynsections.js" type="text/javascript"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script src="search/searchdata.js" type="text/javascript"></script>
<script src="search/search.js" type="text/javascript"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css"/>
<link href="rapids.css" rel="stylesheet" type="text/css"/>
<link href="https://stackpath.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" id="rapids-fa-tag" rel="stylesheet"/><link href="/assets/css/custom.css" id="rapids-selector-css" rel="stylesheet"/></head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea"><div id="rapids-doxygen-container"><div class="rapids-home-container"><a class="rapids-home-container__home-btn" href="/api">Home</a></div><div class="rapids-selector__container rapids-selector--hidden"><div class="rapids-selector__selected">libcudf</div><div class="rapids-selector__menu"><a class="rapids-selector__menu-item" href="/api/clx/stable/api.html">clx</a><a class="rapids-selector__menu-item" href="/api/cudf-java/stable">cudf-java</a><a class="rapids-selector__menu-item" href="/api/cudf/stable/api.html">cudf</a><a class="rapids-selector__menu-item" href="/api/cugraph/stable/api.html">cugraph</a><a class="rapids-selector__menu-item" href="/api/cuml/stable/api.html">cuml</a><a class="rapids-selector__menu-item" href="/api/cusignal/stable/api.html">cusignal</a><a class="rapids-selector__menu-item" href="/api/cuspatial/stable/api.html">cuspatial</a><a class="rapids-selector__menu-item" href="/api/cuxfilter/stable">cuxfilter</a><a class="rapids-selector__menu-item rapids-selector__menu-item--selected" href="/api/libcudf/stable/namespacecudf.html">libcudf</a><a class="rapids-selector__menu-item" href="/api/libcugraph/stable">libcugraph</a><a class="rapids-selector__menu-item" href="/api/libcuml/stable">libcuml</a><a class="rapids-selector__menu-item" href="/api/libnvstrings/stable/annotated.html">libnvstrings</a><a class="rapids-selector__menu-item" href="/api/nvstrings/stable/api.html">nvstrings</a><a class="rapids-selector__menu-item" href="/api/rmm/stable/annotated.html">rmm</a></div></div><div class="rapids-selector__container rapids-selector--hidden"><div class="rapids-selector__selected">nightly (0.15)</div><div class="rapids-selector__menu"><a class="rapids-selector__menu-item rapids-selector__menu-item--selected" href="/api/libcudf/nightly/namespacecudf.html">nightly (0.15)</a><a class="rapids-selector__menu-item" href="/api/libcudf/stable/namespacecudf.html">stable (0.14)</a><a class="rapids-selector__menu-item" href="/api/libcudf/legacy/namespacecudf.html">legacy (0.13)</a></div></div></div>

</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.18 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script src="menudata.js" type="text/javascript"></script>
<script src="menu.js" type="text/javascript"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow" onkeydown="return searchBox.OnSearchSelectKey(event)" onmouseout="return searchBox.OnSearchSelectHide()" onmouseover="return searchBox.OnSearchSelectShow()">
</div>
<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe frameborder="0" id="MSearchResults" name="MSearchResults" src="javascript:void(0)">
</iframe>
</div>
</div><!-- top -->
<div class="header">
<div class="summary">
<a href="#nested-classes">Classes</a> |
<a href="#func-members">Functions</a> </div>
<div class="headertitle">
<div class="title">nvtext Namespace Reference</div> </div>
</div><!--header-->
<div class="contents">
<p>NVText APIs.  
<a href="namespacenvtext.html#details">More...</a></p>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="nested-classes"></a>
Classes</h2></td></tr>
<tr class="memitem:"><td align="right" class="memItemLeft" valign="top">struct  </td><td class="memItemRight" valign="bottom"><a class="el" href="structnvtext_1_1hashed__vocabulary.html">hashed_vocabulary</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft"> </td><td class="mdescRight">The vocabulary data for use with the subword_tokenize function.  <a href="structnvtext_1_1hashed__vocabulary.html#details">More...</a><br/></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2"> </td></tr>
<tr class="memitem:"><td align="right" class="memItemLeft" valign="top">struct  </td><td class="memItemRight" valign="bottom"><a class="el" href="structnvtext_1_1tokenizer__result.html">tokenizer_result</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft"> </td><td class="mdescRight">Result object for the subword_tokenize functions.  <a href="structnvtext_1_1tokenizer__result.html#details">More...</a><br/></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2"> </td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:ga81acc9b2e82f3b35f94c7f5acf77c9bd"><td align="right" class="memItemLeft" valign="top">std::unique_ptr&lt; <a class="el" href="classcudf_1_1column.html">cudf::column</a> &gt; </td><td class="memItemRight" valign="bottom"><a class="el" href="group__nvtext__ngrams.html#ga81acc9b2e82f3b35f94c7f5acf77c9bd">generate_ngrams</a> (<a class="el" href="classcudf_1_1strings__column__view.html">cudf::strings_column_view</a> const &amp;strings, cudf::size_type ngrams=2, <a class="el" href="classcudf_1_1string__scalar.html">cudf::string_scalar</a> const &amp;separator=<a class="el" href="classcudf_1_1string__scalar.html">cudf::string_scalar</a>{"_"}, rmm::mr::device_memory_resource *mr=rmm::mr::get_default_resource())</td></tr>
<tr class="memdesc:ga81acc9b2e82f3b35f94c7f5acf77c9bd"><td class="mdescLeft"> </td><td class="mdescRight">Returns a single column of strings by generating ngrams from a strings column.  <a href="group__nvtext__ngrams.html#ga81acc9b2e82f3b35f94c7f5acf77c9bd">More...</a><br/></td></tr>
<tr class="separator:ga81acc9b2e82f3b35f94c7f5acf77c9bd"><td class="memSeparator" colspan="2"> </td></tr>
<tr class="memitem:ga14f612e504c553286d67e1e952f4794b"><td align="right" class="memItemLeft" valign="top">std::unique_ptr&lt; <a class="el" href="classcudf_1_1column.html">cudf::column</a> &gt; </td><td class="memItemRight" valign="bottom"><a class="el" href="group__nvtext__ngrams.html#ga14f612e504c553286d67e1e952f4794b">generate_character_ngrams</a> (<a class="el" href="classcudf_1_1strings__column__view.html">cudf::strings_column_view</a> const &amp;strings, cudf::size_type ngrams=2, rmm::mr::device_memory_resource *mr=rmm::mr::get_default_resource())</td></tr>
<tr class="memdesc:ga14f612e504c553286d67e1e952f4794b"><td class="mdescLeft"> </td><td class="mdescRight">Generates ngrams of characters within each string.  <a href="group__nvtext__ngrams.html#ga14f612e504c553286d67e1e952f4794b">More...</a><br/></td></tr>
<tr class="separator:ga14f612e504c553286d67e1e952f4794b"><td class="memSeparator" colspan="2"> </td></tr>
<tr class="memitem:gabf8708c4233cb725bcecb748543f3ca5"><td align="right" class="memItemLeft" valign="top">std::unique_ptr&lt; <a class="el" href="classcudf_1_1column.html">cudf::column</a> &gt; </td><td class="memItemRight" valign="bottom"><a class="el" href="group__nvtext__ngrams.html#gabf8708c4233cb725bcecb748543f3ca5">ngrams_tokenize</a> (<a class="el" href="classcudf_1_1strings__column__view.html">cudf::strings_column_view</a> const &amp;strings, cudf::size_type ngrams=2, <a class="el" href="classcudf_1_1string__scalar.html">cudf::string_scalar</a> const &amp;delimiter=<a class="el" href="classcudf_1_1string__scalar.html">cudf::string_scalar</a>{""}, <a class="el" href="classcudf_1_1string__scalar.html">cudf::string_scalar</a> const &amp;separator=<a class="el" href="classcudf_1_1string__scalar.html">cudf::string_scalar</a>{"_"}, rmm::mr::device_memory_resource *mr=rmm::mr::get_default_resource())</td></tr>
<tr class="memdesc:gabf8708c4233cb725bcecb748543f3ca5"><td class="mdescLeft"> </td><td class="mdescRight">Returns a single column of strings by tokenizing the input strings column and then producing ngrams of each string.  <a href="group__nvtext__ngrams.html#gabf8708c4233cb725bcecb748543f3ca5">More...</a><br/></td></tr>
<tr class="separator:gabf8708c4233cb725bcecb748543f3ca5"><td class="memSeparator" colspan="2"> </td></tr>
<tr class="memitem:gae783a4168cb9687c5f22e30f2e4c84ad"><td align="right" class="memItemLeft" valign="top">std::unique_ptr&lt; <a class="el" href="classcudf_1_1column.html">cudf::column</a> &gt; </td><td class="memItemRight" valign="bottom"><a class="el" href="group__nvtext__normalize.html#gae783a4168cb9687c5f22e30f2e4c84ad">normalize_spaces</a> (<a class="el" href="classcudf_1_1strings__column__view.html">cudf::strings_column_view</a> const &amp;strings, rmm::mr::device_memory_resource *mr=rmm::mr::get_default_resource())</td></tr>
<tr class="memdesc:gae783a4168cb9687c5f22e30f2e4c84ad"><td class="mdescLeft"> </td><td class="mdescRight">Returns a new strings column by normalizing the whitespace in each string in the input column.  <a href="group__nvtext__normalize.html#gae783a4168cb9687c5f22e30f2e4c84ad">More...</a><br/></td></tr>
<tr class="separator:gae783a4168cb9687c5f22e30f2e4c84ad"><td class="memSeparator" colspan="2"> </td></tr>
<tr class="memitem:gabb5e181ab7d045ec4c392505a847eeff"><td align="right" class="memItemLeft" valign="top">std::unique_ptr&lt; <a class="el" href="classcudf_1_1column.html">cudf::column</a> &gt; </td><td class="memItemRight" valign="bottom"><a class="el" href="group__nvtext__replace.html#gabb5e181ab7d045ec4c392505a847eeff">replace_tokens</a> (<a class="el" href="classcudf_1_1strings__column__view.html">cudf::strings_column_view</a> const &amp;strings, <a class="el" href="classcudf_1_1strings__column__view.html">cudf::strings_column_view</a> const &amp;targets, <a class="el" href="classcudf_1_1strings__column__view.html">cudf::strings_column_view</a> const &amp;replacements, <a class="el" href="classcudf_1_1string__scalar.html">cudf::string_scalar</a> const &amp;delimiter=<a class="el" href="classcudf_1_1string__scalar.html">cudf::string_scalar</a>{""}, rmm::mr::device_memory_resource *mr=rmm::mr::get_default_resource())</td></tr>
<tr class="memdesc:gabb5e181ab7d045ec4c392505a847eeff"><td class="mdescLeft"> </td><td class="mdescRight">Replaces specified tokens with corresponding replacement strings.  <a href="group__nvtext__replace.html#gabb5e181ab7d045ec4c392505a847eeff">More...</a><br/></td></tr>
<tr class="separator:gabb5e181ab7d045ec4c392505a847eeff"><td class="memSeparator" colspan="2"> </td></tr>
<tr class="memitem:a8603f724aa881a6608d26225a227e795"><td align="right" class="memItemLeft" valign="top"><a class="el" href="structnvtext_1_1hashed__vocabulary.html">hashed_vocabulary</a> </td><td class="memItemRight" valign="bottom"><a class="el" href="namespacenvtext.html#a8603f724aa881a6608d26225a227e795">load_vocabulary_file</a> (std::string const &amp;filename_hashed_vocabulary, rmm::mr::device_memory_resource *mr=rmm::mr::get_default_resource())</td></tr>
<tr class="memdesc:a8603f724aa881a6608d26225a227e795"><td class="mdescLeft"> </td><td class="mdescRight">Load the hashed vocabulary file into device memory.  <a href="namespacenvtext.html#a8603f724aa881a6608d26225a227e795">More...</a><br/></td></tr>
<tr class="separator:a8603f724aa881a6608d26225a227e795"><td class="memSeparator" colspan="2"> </td></tr>
<tr class="memitem:ad725d85bccf2869740328e42a3db6ed2"><td align="right" class="memItemLeft" valign="top"><a class="el" href="structnvtext_1_1tokenizer__result.html">tokenizer_result</a> </td><td class="memItemRight" valign="bottom"><a class="el" href="namespacenvtext.html#ad725d85bccf2869740328e42a3db6ed2">subword_tokenize</a> (<a class="el" href="classcudf_1_1strings__column__view.html">cudf::strings_column_view</a> const &amp;strings, std::string const &amp;filename_hashed_vocabulary, uint32_t max_sequence_length, uint32_t stride, bool do_lower_case, bool do_truncate, uint32_t max_num_strings, uint32_t max_num_chars, uint32_t max_rows_tensor, rmm::mr::device_memory_resource *mr=rmm::mr::get_default_resource())</td></tr>
<tr class="memdesc:ad725d85bccf2869740328e42a3db6ed2"><td class="mdescLeft"> </td><td class="mdescRight">Creates a tokenizer that cleans the text, splits it into tokens and returns token-ids from an input vocabulary.  <a href="namespacenvtext.html#ad725d85bccf2869740328e42a3db6ed2">More...</a><br/></td></tr>
<tr class="separator:ad725d85bccf2869740328e42a3db6ed2"><td class="memSeparator" colspan="2"> </td></tr>
<tr class="memitem:a5cd7e1cc61dd86b1d0d558f5a768acce"><td align="right" class="memItemLeft" valign="top"><a class="el" href="structnvtext_1_1tokenizer__result.html">tokenizer_result</a> </td><td class="memItemRight" valign="bottom"><a class="el" href="namespacenvtext.html#a5cd7e1cc61dd86b1d0d558f5a768acce">subword_tokenize</a> (<a class="el" href="classcudf_1_1strings__column__view.html">cudf::strings_column_view</a> const &amp;strings, <a class="el" href="structnvtext_1_1hashed__vocabulary.html">hashed_vocabulary</a> const &amp;vocabulary_table, uint32_t max_sequence_length, uint32_t stride, bool do_lower_case, bool do_truncate, uint32_t max_num_strings, uint32_t max_num_chars, uint32_t max_rows_tensor, rmm::mr::device_memory_resource *mr=rmm::mr::get_default_resource())</td></tr>
<tr class="memdesc:a5cd7e1cc61dd86b1d0d558f5a768acce"><td class="mdescLeft"> </td><td class="mdescRight">Creates a tokenizer that cleans the text, splits it into tokens and returns token-ids from an input vocabulary.  <a href="namespacenvtext.html#a5cd7e1cc61dd86b1d0d558f5a768acce">More...</a><br/></td></tr>
<tr class="separator:a5cd7e1cc61dd86b1d0d558f5a768acce"><td class="memSeparator" colspan="2"> </td></tr>
<tr class="memitem:ga5a6377b3226915576a277c291c9abf77"><td align="right" class="memItemLeft" valign="top">std::unique_ptr&lt; <a class="el" href="classcudf_1_1column.html">cudf::column</a> &gt; </td><td class="memItemRight" valign="bottom"><a class="el" href="group__nvtext__tokenize.html#ga5a6377b3226915576a277c291c9abf77">tokenize</a> (<a class="el" href="classcudf_1_1strings__column__view.html">cudf::strings_column_view</a> const &amp;strings, <a class="el" href="classcudf_1_1string__scalar.html">cudf::string_scalar</a> const &amp;delimiter=<a class="el" href="classcudf_1_1string__scalar.html">cudf::string_scalar</a>{""}, rmm::mr::device_memory_resource *mr=rmm::mr::get_default_resource())</td></tr>
<tr class="memdesc:ga5a6377b3226915576a277c291c9abf77"><td class="mdescLeft"> </td><td class="mdescRight">Returns a single column of strings by tokenizing the input strings column using the provided characters as delimiters.  <a href="group__nvtext__tokenize.html#ga5a6377b3226915576a277c291c9abf77">More...</a><br/></td></tr>
<tr class="separator:ga5a6377b3226915576a277c291c9abf77"><td class="memSeparator" colspan="2"> </td></tr>
<tr class="memitem:ga86420ed6ea932602cfd195385b153959"><td align="right" class="memItemLeft" valign="top">std::unique_ptr&lt; <a class="el" href="classcudf_1_1column.html">cudf::column</a> &gt; </td><td class="memItemRight" valign="bottom"><a class="el" href="group__nvtext__tokenize.html#ga86420ed6ea932602cfd195385b153959">tokenize</a> (<a class="el" href="classcudf_1_1strings__column__view.html">cudf::strings_column_view</a> const &amp;strings, <a class="el" href="classcudf_1_1strings__column__view.html">cudf::strings_column_view</a> const &amp;delimiters, rmm::mr::device_memory_resource *mr=rmm::mr::get_default_resource())</td></tr>
<tr class="memdesc:ga86420ed6ea932602cfd195385b153959"><td class="mdescLeft"> </td><td class="mdescRight">Returns a single column of strings by tokenizing the input strings column using multiple strings as delimiters.  <a href="group__nvtext__tokenize.html#ga86420ed6ea932602cfd195385b153959">More...</a><br/></td></tr>
<tr class="separator:ga86420ed6ea932602cfd195385b153959"><td class="memSeparator" colspan="2"> </td></tr>
<tr class="memitem:ga42e284f58436d9eb3b0a4b5985bed67b"><td align="right" class="memItemLeft" valign="top">std::unique_ptr&lt; <a class="el" href="classcudf_1_1column.html">cudf::column</a> &gt; </td><td class="memItemRight" valign="bottom"><a class="el" href="group__nvtext__tokenize.html#ga42e284f58436d9eb3b0a4b5985bed67b">count_tokens</a> (<a class="el" href="classcudf_1_1strings__column__view.html">cudf::strings_column_view</a> const &amp;strings, <a class="el" href="classcudf_1_1string__scalar.html">cudf::string_scalar</a> const &amp;delimiter=<a class="el" href="classcudf_1_1string__scalar.html">cudf::string_scalar</a>{""}, rmm::mr::device_memory_resource *mr=rmm::mr::get_default_resource())</td></tr>
<tr class="memdesc:ga42e284f58436d9eb3b0a4b5985bed67b"><td class="mdescLeft"> </td><td class="mdescRight">Returns the number of tokens in each string of a strings column.  <a href="group__nvtext__tokenize.html#ga42e284f58436d9eb3b0a4b5985bed67b">More...</a><br/></td></tr>
<tr class="separator:ga42e284f58436d9eb3b0a4b5985bed67b"><td class="memSeparator" colspan="2"> </td></tr>
<tr class="memitem:ga5fc4729449ab49a49437c08c49aa0c6f"><td align="right" class="memItemLeft" valign="top">std::unique_ptr&lt; <a class="el" href="classcudf_1_1column.html">cudf::column</a> &gt; </td><td class="memItemRight" valign="bottom"><a class="el" href="group__nvtext__tokenize.html#ga5fc4729449ab49a49437c08c49aa0c6f">count_tokens</a> (<a class="el" href="classcudf_1_1strings__column__view.html">cudf::strings_column_view</a> const &amp;strings, <a class="el" href="classcudf_1_1strings__column__view.html">cudf::strings_column_view</a> const &amp;delimiters, rmm::mr::device_memory_resource *mr=rmm::mr::get_default_resource())</td></tr>
<tr class="memdesc:ga5fc4729449ab49a49437c08c49aa0c6f"><td class="mdescLeft"> </td><td class="mdescRight">Returns the number of tokens in each string of a strings column by using multiple strings delimiters to identify tokens in each string.  <a href="group__nvtext__tokenize.html#ga5fc4729449ab49a49437c08c49aa0c6f">More...</a><br/></td></tr>
<tr class="separator:ga5fc4729449ab49a49437c08c49aa0c6f"><td class="memSeparator" colspan="2"> </td></tr>
<tr class="memitem:gaf24b3e3b4b57ac50f78a53144e2545a6"><td align="right" class="memItemLeft" valign="top">std::unique_ptr&lt; <a class="el" href="classcudf_1_1column.html">cudf::column</a> &gt; </td><td class="memItemRight" valign="bottom"><a class="el" href="group__nvtext__tokenize.html#gaf24b3e3b4b57ac50f78a53144e2545a6">character_tokenize</a> (<a class="el" href="classcudf_1_1strings__column__view.html">cudf::strings_column_view</a> const &amp;strings, rmm::mr::device_memory_resource *mr=rmm::mr::get_default_resource())</td></tr>
<tr class="memdesc:gaf24b3e3b4b57ac50f78a53144e2545a6"><td class="mdescLeft"> </td><td class="mdescRight">Returns a single column of strings by converting each character to a string.  <a href="group__nvtext__tokenize.html#gaf24b3e3b4b57ac50f78a53144e2545a6">More...</a><br/></td></tr>
<tr class="separator:gaf24b3e3b4b57ac50f78a53144e2545a6"><td class="memSeparator" colspan="2"> </td></tr>
</table>
<a id="details" name="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><p>NVText APIs. </p>
</div><h2 class="groupheader">Function Documentation</h2>
<a id="a8603f724aa881a6608d26225a227e795"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8603f724aa881a6608d26225a227e795">◆ </a></span>load_vocabulary_file()</h2>
<div class="memitem">
<div class="memproto">
<table class="memname">
<tr>
<td class="memname"><a class="el" href="structnvtext_1_1hashed__vocabulary.html">hashed_vocabulary</a> nvtext::load_vocabulary_file </td>
<td>(</td>
<td class="paramtype">std::string const &amp; </td>
<td class="paramname"><em>filename_hashed_vocabulary</em>, </td>
</tr>
<tr>
<td class="paramkey"></td>
<td></td>
<td class="paramtype">rmm::mr::device_memory_resource * </td>
<td class="paramname"><em>mr</em> = <code>rmm::mr::get_default_resource()</code> </td>
</tr>
<tr>
<td></td>
<td>)</td>
<td></td><td></td>
</tr>
</table>
</div><div class="memdoc">
<p>Load the hashed vocabulary file into device memory. </p>
<p>The object here can be used to call the subword_tokenize without incurring the cost of loading the same file each time.</p>
<dl class="exception"><dt>Exceptions</dt><dd>
<table class="exception">
<tr><td class="paramname"><a class="el" href="structcudf_1_1logic__error.html" title="Exception thrown when logical precondition is violated.">cudf::logic_error</a></td><td>if the <code>filename_hashed_vocabulary</code> could not be opened.</td></tr>
</table>
</dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
<table class="params">
<tr><td class="paramname">filename_hashed_vocabulary</td><td>A path to the preprocessed vocab.txt file. Note that this is the file AFTER python/perfect_hash.py has been used for preprocessing. </td></tr>
<tr><td class="paramname">mr</td><td>Memory resource to allocate any returned objects. </td></tr>
</table>
</dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>vocabulary hash-table elements </dd></dl>
</div>
</div>
<a id="a5cd7e1cc61dd86b1d0d558f5a768acce"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5cd7e1cc61dd86b1d0d558f5a768acce">◆ </a></span>subword_tokenize() <span class="overload">[1/2]</span></h2>
<div class="memitem">
<div class="memproto">
<table class="memname">
<tr>
<td class="memname"><a class="el" href="structnvtext_1_1tokenizer__result.html">tokenizer_result</a> nvtext::subword_tokenize </td>
<td>(</td>
<td class="paramtype"><a class="el" href="classcudf_1_1strings__column__view.html">cudf::strings_column_view</a> const &amp; </td>
<td class="paramname"><em>strings</em>, </td>
</tr>
<tr>
<td class="paramkey"></td>
<td></td>
<td class="paramtype"><a class="el" href="structnvtext_1_1hashed__vocabulary.html">hashed_vocabulary</a> const &amp; </td>
<td class="paramname"><em>vocabulary_table</em>, </td>
</tr>
<tr>
<td class="paramkey"></td>
<td></td>
<td class="paramtype">uint32_t </td>
<td class="paramname"><em>max_sequence_length</em>, </td>
</tr>
<tr>
<td class="paramkey"></td>
<td></td>
<td class="paramtype">uint32_t </td>
<td class="paramname"><em>stride</em>, </td>
</tr>
<tr>
<td class="paramkey"></td>
<td></td>
<td class="paramtype">bool </td>
<td class="paramname"><em>do_lower_case</em>, </td>
</tr>
<tr>
<td class="paramkey"></td>
<td></td>
<td class="paramtype">bool </td>
<td class="paramname"><em>do_truncate</em>, </td>
</tr>
<tr>
<td class="paramkey"></td>
<td></td>
<td class="paramtype">uint32_t </td>
<td class="paramname"><em>max_num_strings</em>, </td>
</tr>
<tr>
<td class="paramkey"></td>
<td></td>
<td class="paramtype">uint32_t </td>
<td class="paramname"><em>max_num_chars</em>, </td>
</tr>
<tr>
<td class="paramkey"></td>
<td></td>
<td class="paramtype">uint32_t </td>
<td class="paramname"><em>max_rows_tensor</em>, </td>
</tr>
<tr>
<td class="paramkey"></td>
<td></td>
<td class="paramtype">rmm::mr::device_memory_resource * </td>
<td class="paramname"><em>mr</em> = <code>rmm::mr::get_default_resource()</code> </td>
</tr>
<tr>
<td></td>
<td>)</td>
<td></td><td></td>
</tr>
</table>
</div><div class="memdoc">
<p>Creates a tokenizer that cleans the text, splits it into tokens and returns token-ids from an input vocabulary. </p>
<p>The strings are first normalized by converting to lower-case, removing punctuation, replacing a select set of multi-byte characters and whitespace characters.</p>
<p>The strings are then tokenized by using whitespace as a delimiter. Consecutive delimiters are ignored. Each token is then assigned a 4-byte token-id mapped from the provided vocabulary table.</p>
<p>Essentially each string is converted into one or more vectors of token-ids in the output column. The total number of these vectors x <code>max_sequence_length</code> is the size of the output column.</p>
<dl class="exception"><dt>Exceptions</dt><dd>
<table class="exception">
<tr><td class="paramname"><a class="el" href="structcudf_1_1logic__error.html" title="Exception thrown when logical precondition is violated.">cudf::logic_error</a></td><td>if <code>stride &gt; max_sequence_length</code> </td></tr>
<tr><td class="paramname"><a class="el" href="structcudf_1_1logic__error.html" title="Exception thrown when logical precondition is violated.">cudf::logic_error</a></td><td>if <code>max_sequence_length * max_rows_tensor</code> is larger than the max value for cudf::size_type</td></tr>
</table>
</dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
<table class="params">
<tr><td class="paramname">strings</td><td>The input strings to tokenize. </td></tr>
<tr><td class="paramname">filename_hashed_vocabulary</td><td>A path to the preprocessed vocab.txt file. Note that this is the file AFTER python/perfect_hash.py has been used for preprocessing. </td></tr>
<tr><td class="paramname">max_sequence_length</td><td>Limit of the number of token-ids per row in final tensor for each string. </td></tr>
<tr><td class="paramname">stride</td><td>Each row in the output token-ids will replicate <code>max_sequence_length - stride</code> the token-ids from the previous row, unless it is the first string. </td></tr>
<tr><td class="paramname">do_lower_case</td><td>If true, the tokenizer will convert uppercase characters in the input stream to lower-case and strip accents from those characters. If false, accented and uppercase characters are not transformed. </td></tr>
<tr><td class="paramname">do_truncate</td><td>If true, the tokenizer will discard all the token-ids after <code>max_sequence_length</code> for each input string. If false, it will use a new row in the output token-ids to continue generating the output. </td></tr>
<tr><td class="paramname">max_num_strings</td><td>Maximum number of input strings for instantiating the tokenizer. Used for allocating temporary working memory on the GPU. If the input contains a larger number of strings, behavior is undefined. </td></tr>
<tr><td class="paramname">max_num_chars</td><td>Maximum number of characters for instantiating the tokenizer. Used for allocating temporary working memory on the GPU. If input contains larger number of characters, behavior is undefined. </td></tr>
<tr><td class="paramname">max_rows_tensor</td><td>Maximum number of rows for the output token-ids expected to be generated by the tokenizer. Used for allocating temporary working memory on the GPU device. If the output generates a larger number of rows, behavior is undefined. </td></tr>
<tr><td class="paramname">mr</td><td>Memory resource to allocate any returned objects. </td></tr>
</table>
</dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>token-ids, attention-mask, and metadata</dd></dl>
<p>This function differs from the one above by only the hashed vocabulary parameter. The file can be pre-loaded using the <a class="el" href="namespacenvtext.html#a8603f724aa881a6608d26225a227e795">load_vocabulary_file</a> API and then passed in place of the file name in a call to this API.</p>
<dl class="params"><dt>Parameters</dt><dd>
<table class="params">
<tr><td class="paramname">vocabulary_table</td><td>The vocabulary table pre-loaded into this object. </td></tr>
</table>
</dd>
</dl>
</div>
</div>
<a id="ad725d85bccf2869740328e42a3db6ed2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad725d85bccf2869740328e42a3db6ed2">◆ </a></span>subword_tokenize() <span class="overload">[2/2]</span></h2>
<div class="memitem">
<div class="memproto">
<table class="memname">
<tr>
<td class="memname"><a class="el" href="structnvtext_1_1tokenizer__result.html">tokenizer_result</a> nvtext::subword_tokenize </td>
<td>(</td>
<td class="paramtype"><a class="el" href="classcudf_1_1strings__column__view.html">cudf::strings_column_view</a> const &amp; </td>
<td class="paramname"><em>strings</em>, </td>
</tr>
<tr>
<td class="paramkey"></td>
<td></td>
<td class="paramtype">std::string const &amp; </td>
<td class="paramname"><em>filename_hashed_vocabulary</em>, </td>
</tr>
<tr>
<td class="paramkey"></td>
<td></td>
<td class="paramtype">uint32_t </td>
<td class="paramname"><em>max_sequence_length</em>, </td>
</tr>
<tr>
<td class="paramkey"></td>
<td></td>
<td class="paramtype">uint32_t </td>
<td class="paramname"><em>stride</em>, </td>
</tr>
<tr>
<td class="paramkey"></td>
<td></td>
<td class="paramtype">bool </td>
<td class="paramname"><em>do_lower_case</em>, </td>
</tr>
<tr>
<td class="paramkey"></td>
<td></td>
<td class="paramtype">bool </td>
<td class="paramname"><em>do_truncate</em>, </td>
</tr>
<tr>
<td class="paramkey"></td>
<td></td>
<td class="paramtype">uint32_t </td>
<td class="paramname"><em>max_num_strings</em>, </td>
</tr>
<tr>
<td class="paramkey"></td>
<td></td>
<td class="paramtype">uint32_t </td>
<td class="paramname"><em>max_num_chars</em>, </td>
</tr>
<tr>
<td class="paramkey"></td>
<td></td>
<td class="paramtype">uint32_t </td>
<td class="paramname"><em>max_rows_tensor</em>, </td>
</tr>
<tr>
<td class="paramkey"></td>
<td></td>
<td class="paramtype">rmm::mr::device_memory_resource * </td>
<td class="paramname"><em>mr</em> = <code>rmm::mr::get_default_resource()</code> </td>
</tr>
<tr>
<td></td>
<td>)</td>
<td></td><td></td>
</tr>
</table>
</div><div class="memdoc">
<p>Creates a tokenizer that cleans the text, splits it into tokens and returns token-ids from an input vocabulary. </p>
<p>The strings are first normalized by converting to lower-case, removing punctuation, replacing a select set of multi-byte characters and whitespace characters.</p>
<p>The strings are then tokenized by using whitespace as a delimiter. Consecutive delimiters are ignored. Each token is then assigned a 4-byte token-id mapped from the provided vocabulary table.</p>
<p>Essentially each string is converted into one or more vectors of token-ids in the output column. The total number of these vectors x <code>max_sequence_length</code> is the size of the output column.</p>
<dl class="exception"><dt>Exceptions</dt><dd>
<table class="exception">
<tr><td class="paramname"><a class="el" href="structcudf_1_1logic__error.html" title="Exception thrown when logical precondition is violated.">cudf::logic_error</a></td><td>if <code>stride &gt; max_sequence_length</code> </td></tr>
<tr><td class="paramname"><a class="el" href="structcudf_1_1logic__error.html" title="Exception thrown when logical precondition is violated.">cudf::logic_error</a></td><td>if <code>max_sequence_length * max_rows_tensor</code> is larger than the max value for cudf::size_type</td></tr>
</table>
</dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
<table class="params">
<tr><td class="paramname">strings</td><td>The input strings to tokenize. </td></tr>
<tr><td class="paramname">filename_hashed_vocabulary</td><td>A path to the preprocessed vocab.txt file. Note that this is the file AFTER python/perfect_hash.py has been used for preprocessing. </td></tr>
<tr><td class="paramname">max_sequence_length</td><td>Limit of the number of token-ids per row in final tensor for each string. </td></tr>
<tr><td class="paramname">stride</td><td>Each row in the output token-ids will replicate <code>max_sequence_length - stride</code> the token-ids from the previous row, unless it is the first string. </td></tr>
<tr><td class="paramname">do_lower_case</td><td>If true, the tokenizer will convert uppercase characters in the input stream to lower-case and strip accents from those characters. If false, accented and uppercase characters are not transformed. </td></tr>
<tr><td class="paramname">do_truncate</td><td>If true, the tokenizer will discard all the token-ids after <code>max_sequence_length</code> for each input string. If false, it will use a new row in the output token-ids to continue generating the output. </td></tr>
<tr><td class="paramname">max_num_strings</td><td>Maximum number of input strings for instantiating the tokenizer. Used for allocating temporary working memory on the GPU. If the input contains a larger number of strings, behavior is undefined. </td></tr>
<tr><td class="paramname">max_num_chars</td><td>Maximum number of characters for instantiating the tokenizer. Used for allocating temporary working memory on the GPU. If input contains larger number of characters, behavior is undefined. </td></tr>
<tr><td class="paramname">max_rows_tensor</td><td>Maximum number of rows for the output token-ids expected to be generated by the tokenizer. Used for allocating temporary working memory on the GPU device. If the output generates a larger number of rows, behavior is undefined. </td></tr>
<tr><td class="paramname">mr</td><td>Memory resource to allocate any returned objects. </td></tr>
</table>
</dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>token-ids, attention-mask, and metadata </dd></dl>
</div>
</div>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by  <a href="http://www.doxygen.org/index.html">
<img alt="doxygen" class="footer" src="doxygen.png"/>
</a> 1.8.18
</small></address>
<script defer id="rapids-selector-js" src="/assets/js/custom.js"></script></body>
</html>
